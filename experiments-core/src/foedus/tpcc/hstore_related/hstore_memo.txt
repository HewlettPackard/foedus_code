First, sudo yum install ant ant-*
Otherwise
[kimurhid@tmsim-4 h-store]$ ant
Buildfile: /dev/shm/h-store/build.xml
  [taskdef] Could not load definitions from resource net/sf/antcontrib/antcontrib.properties. It could not be found.



http://hstore.cs.brown.edu/documentation/deployment/client-configuration/

cd /dev/shm
git clone --depth 1 http://github.com/apavlo/h-store.git
Or tar -xf ~/h-store_copy_20141019.tar.gz

git clone --depth 1 http://245-1.bfc.hpl.hp.com/kimurhid/h-store.git

In our network, you might need:
git config --global http.proxy http://web-proxy.hpl.hp.com:8088

ant build

ssh-keygen -t dsa
< Enter a few times >

cat ~/.ssh/id_dsa.pub >> ~/.ssh/authorized_keys

AND ALSO SET PERMISSION!
chmod 644 ~/.ssh/authorized_keys

/etc/ssh/sshd_config
RSAAuthentication yes
PubkeyAuthentication yes
PermitEmptyPasswords yes

ssh localhost date


parameter templates and why

-Dsite.jvm_asserts=false
To increase performance

-Dsite.cpu_affinity=false
Andy's recommendation.
=> Well, actually this slows it down at least on Z820.
we should experiment both cpu affinity true and false

-Dclient.blocking=false
To increase throughput

-Dclient.memory=512
In MB. Adjust depending on machine size.

-Dsite.memory=8192
In MB. Adjust depending on machine size.

-Dglobal.memory=2048
Increase only on DragonHawk. Otherwise won't cause an issue.

-Dclient.txnrate=10000

-Dclient.threads_per_host=50
Adjust depending on machine size.


-Dneworder_multip=false
-Dneworder_multip=true
-Dneworder_multip_mix=1
These can't be specified from command line. has to generate tpcc.properties.


-Dhosts="localhost:0:0-3;localhost:1:4-7"
Vary it

Concatenated

ant hstore-prepare hstore-benchmark -Dproject=tpcc -Dsite.jvm_asserts=false -Dclient.blocking=false -Dclient.memory=512 -Dsite.memory=8192 -Dglobal.memory=2048 -Dclient.txnrate=10000 -Dclient.threads_per_host=50 -Dhosts="localhost:0:0-3;localhost:1:4-7"

kimurhid         soft    nproc           65536
kimurhid         hard    nproc           65536

Note, be aware of this error:
  hstore-site:
  OpenJDK 64-Bit Server VM warning: Max heap size too large for Compressed Oops
Keep heap sizes within 32GB.


Edit this file:
emacs -nw src/frontend/org/voltdb/processtools/ProcessSetManager.java

Change line 77
    private static final int POLLING_DELAY = 2000; // ms
to
    private static final int POLLING_DELAY = 60000; // ms

Change line 329:
  this(null, false, 10000, null);
to
  this(null, false, 60000, null);


Then ant


http://hstore.cs.brown.edu/documentation/deployment/anti-caching/
http://hstore.cs.brown.edu/documentation/deployment/command-logging/

ant hstore-prepare -Dproject=tpcc -Devictable="HISTORY,CUSTOMER,ORDERS,ORDER_LINE" -Dhosts="localhost:0:0-7"

ant hstore-benchmark -Dproject=tpcc -Dsite.anticache_enable=true -Dsite.anticache_dir=/testnvm/anticache \
  -Dsite.commandlog_enable=true -Dsite.commandlog_dir="/testnvm/commandlog/" \
  -Dsite.commandlog_timeout=500 -Dsite.jvm_asserts=false -Dclient.blocking=false \
  -Dsite.cpu_affinity=true -Dclient.memory=512 -Dsite.memory=8192 -Dglobal.memory=2048 \
  -Dclient.txnrate=2000 -Dclient.threads_per_host=20 \
  -Dhosts="localhost:0:0-7"

sudo umount /testnvm
sudo mount -t nvmfs -o rd_delay_ns_fixed=0,wr_delay_ns_fixed=0,rd_delay_ns_per_kb=0,wr_delay_ns_per_kb=0,cpu_freq_mhz=2800,size=1000000m nvmfs /testnvm
mkdir /testnvm/anticache;mkdir /testnvm/commandlog


sudo umount /testnvm
sudo mount -t nvmfs -o rd_delay_ns_fixed=10000000,wr_delay_ns_fixed=10000000,rd_delay_ns_per_kb=0,wr_delay_ns_per_kb=0,cpu_freq_mhz=2800,size=1000000m nvmfs /testnvm
mkdir /testnvm/anticache;mkdir /testnvm/commandlog

"site.anticache_batching"
Default:  false
Permitted Tye:  boolean
Turn on batching for anticaching

Mmm, should we use it? let's try...

ant hstore-benchmark -Dproject=tpcc -Dsite.anticache_enable=true -Dsite.anticache_dir=/testnvm/anticache \
  -Dsite.commandlog_enable=true -Dsite.commandlog_dir="/testnvm/commandlog/" \
  -Dsite.commandlog_timeout=500 -Dsite.jvm_asserts=false -Dclient.blocking=false \
  -Dsite.cpu_affinity=true -Dclient.memory=512 -Dsite.memory=8192 -Dglobal.memory=2048 \
  -Dclient.txnrate=2000 -Dclient.threads_per_host=20 -Dsite.anticache_batching=true \
  -Dhosts="localhost:0:0-7"
No, it doesn't help. Actually it causes crashes.


-- Notes on anti-cache issue (2015 Jan)
We encountered it back in Nov, but lost the context after 3 months. Let's keep note this time.
There are two issues.
 1. The hang/crash due to buffer overrun after retrieval from anti cache
 2. The hang when some transactions retrieves from remote anti cache

1 is solved by the 2MB-buffer fix by Michael. It's NOT pushed to the master, so do not forget to
apply.
2 is still unsolved. Root cause not known either. The only reliable workaround so far is to
disable remote transactions to use anti cache. In the paper we do this. So, only the H-store
line is remote=0.


-- OLAP experiment (2015 Jan)
cd src/benchmarks/org/voltdb/benchmark/tpcc/
Open TPCCConstants.java
MAX_OL_CNT to 500
Edit FREQUENCY_xxx. STOCK_LEVEL and ORDER_STATUS 50. Others 0.
**Build clean**. For some reason, ant didn't catch the change at least once... clock skew?
To make sure, we should edit TPCCLoader.java L798

        LOG.info(String.format("Loading %d warehouses using %d load threads", warehouseIds.size(), m_loadThreads.length));
        to be
        LOG.info(String.format("Loading %d warehouses using %d load threads. MAX_OL_CNT=%d", warehouseIds.size(), m_loadThreads.length, TPCCConstants.MAX_OL_CNT));


ant clean
ant build

Examples:

ant hstore-prepare -Dproject=tpcc -Dhosts="localhost:0:0-7"

ant hstore-benchmark -Dproject=tpcc -Dsite.jvm_asserts=false -Dclient.blocking=false \
  -Dsite.cpu_affinity=true -Dclient.memory=512 -Dsite.memory=8192 -Dglobal.memory=2048 \
  -Dclient.txnrate=2000 -Dclient.threads_per_host=20 \
  -Dhosts="localhost:0:0-7"


ant hstore-benchmark -Dproject=tpcc -Dsite.jvm_asserts=false -Dclient.blocking=false \
  -Dsite.cpu_affinity=true -Dclient.memory=512 -Dsite.memory=25000 -Dglobal.memory=2048 \
  -Dclient.txnrate=2000 -Dclient.threads_per_host=20 \
  -Dhosts="localhost:0:0-7"

 Mmm, errors on data loading. probably outofmem. but we can't exceed 32GB oops limit.
 try small.
ant hstore-prepare -Dproject=tpcc -Dhosts="localhost:0:0-1"
ant hstore-benchmark -Dproject=tpcc -Dsite.jvm_asserts=false -Dclient.blocking=false \
  -Dsite.cpu_affinity=true -Dclient.memory=1024 -Dsite.memory=20000 -Dglobal.memory=2048 \
  -Dclient.txnrate=2000 -Dclient.threads_per_host=20 \
  -Dhosts="localhost:0:0-1"

wut. even this fails.
ohh yeah, forgot about this issue:
  https://github.com/apavlo/h-store/issues/180

mmm, it fails even after this.

[java] 11:59:02,598 WARN  - Hit with RuntimeException from Load Thread 0. Halting the loading process...
[java] java.lang.RuntimeException: java.lang.RuntimeException: Error when trying load data for 'ORDER_LINE'
[java] 11:59:02,598 INFO  - Waiting for all threads to clean themselves up
[java]     at org.voltdb.benchmark.tpcc.TPCCLoader.load(TPCCLoader.java:823)11:59:02,598 INFO  - Finished loading all warehouses
[java]
[java]     at edu.brown.api.Loader.runLoop(Loader.java:15)
[java] 11:59:02,601 ERROR - Unexpected error from worker-000
[java]     at edu.brown.api.ControlWorker.run(ControlWorker.java:59)
[java] java.lang.RuntimeException: java.lang.RuntimeException: java.lang.RuntimeException: Error when trying load data for 'ORDER_LINE'Caused by: java.lang.RuntimeException: Error when trying load data for 'ORDER_LINE'
[java]
[java]     at edu.brown.api.ControlWorker.run(ControlWorker.java:66)
[java]     at edu.brown.api.BenchmarkComponent.loadVoltTable(BenchmarkComponent.java:1045)
[java] Caused by: java.lang.RuntimeException: java.lang.RuntimeException: Error when trying load data for 'ORDER_LINE'
[java]     at org.voltdb.benchmark.tpcc.TPCCLoader$LoadThread.commitDataTables_VoltDB(TPCCLoader.java:638) at org.voltdb.benchmark.tpcc.TPCCLoader.load(TPCCLoader.java:823)
[java]
[java]     at org.voltdb.benchmark.tpcc.TPCCLoader$LoadThread.commitDataTables(TPCCLoader.java:615)
[java]     at edu.brown.api.Loader.runLoop(Loader.java:15)
[java]     at org.voltdb.benchmark.tpcc.TPCCLoader$LoadThread.makeWarehouse(TPCCLoader.java:560)   at edu.brown.api.ControlWorker.run(ControlWorker.java:59)
[java]
[java]     at org.voltdb.benchmark.tpcc.TPCCLoader$LoadThread.run(TPCCLoader.java:195)Caused by: java.lang.RuntimeException: Error when trying load data for 'ORDER_LINE'
[java]
[java] Caused by: org.voltdb.client.ProcCallException: Connection to database host (localhost) was lost before a response was received     at edu.brown.api.BenchmarkComponent.loadVoltTable(BenchmarkComponent.java:1045)
[java]
[java]     at org.voltdb.client.ClientImpl.callProcedure(ClientImpl.java:249)      at org.voltdb.benchmark.tpcc.TPCCLoader$LoadThread.commitDataTables_VoltDB(TPCCLoader.java:638)
[java]
[java]     at org.voltdb.client.ClientImpl.callProcedure(ClientImpl.java:188)      at org.voltdb.benchmark.tpcc.TPCCLoader$LoadThread.commitDataTables(TPCCLoader.java:615)



ant hstore-prepare -Dproject=tpcc -Dhosts="localhost:0:0"
ant hstore-benchmark -Dproject=tpcc -Dsite.jvm_asserts=false -Dclient.blocking=false \
  -Dsite.cpu_affinity=true -Dclient.memory=1024 -Dsite.memory=8192 -Dglobal.memory=2048 \
  -Dclient.txnrate=2000 -Dclient.threads_per_host=20 \
  -Dhosts="localhost:0:0"


Ahhh, figured it out. TPCCLoader.java buffers too many rows that cause buffer overflow.
TPCCLoader.java  makeWarehouse(). add commitDataTables(w_id) in the district loop to flush
it for each district. and remove the one out of the loop.
Now it works, but even a single-partition load took 4 minutes.

ant hstore-benchmark -Dproject=tpcc -Dsite.jvm_asserts=false -Dclient.blocking=false \
  -Dsite.cpu_affinity=true -Dclient.memory=1024 -Dsite.memory=1024 -Dglobal.memory=2048 \
  -Dclient.txnrate=2000 -Dclient.threads_per_host=20 \
  -Dhosts="localhost:0:0"
Okay, this works fine, too. The memory usage on top is around 2.5GB in this case.
Most memory consumption is in native side, so site.memory doesn't matter much I guess.
x8 will be 20GB per site.


